主题是如何有效的利用硬件的计算资源   

与GPU的通用计算方式（如CUDA）不同，CUDA是以计算资源为中心的，而SSE指令集是以数据为中心的。

# 不要迷信SSE-AVX
实际上CPU中的计算单元占用的晶圆面积不是最主要的（还有取指，解码，换存，分支预测等等）。也就是说，计算资源是很有限的。   
SSE-AVX并不会使计算资源增加，之所以能带来性能的提升，只是C++等语言编译后的程序对计算资源的利用率不足而已（本来就不多，利用率还不够）。另外，编译器也在成长，现在的编译器已经可以自动将一些代码转换为SIMD方式执行以提高效率。   

另外，通过乱序执行和同步多线程，可以提高计算资源的使用效率。现代CPU通过多线程就能得到比较不错的计算效果（这里线程的切换有一定的开销），效果不见得比simd差多少。

# 什么时候使用SSE-AVX
SSE-AVX 指令的优势，在io的控制，和细节的处理上。通过精心的编程可以最大限度的利用硬件的能力，绕过硬件的限制（很多时候是io能力不足，如内存读取延迟，缓存污染等）。不过这对编程人员的要求同样很高。使用指令集提升性能，如果要做到极致，要求对硬件有很深刻的理解。从经济学上讲，程序的边际成本往往接近于0 ，何时使用归化到一个成本和利益的问题：

* 成本：学习硬件的细节，学习相关编程付出的努力，调优等过程消耗的时间，随着硬件更新对变化进行适应消耗的精力等。
* 利益：获得的性能提升，SSE-AVX的提升在1.x - 10左右，更偏向于1.x。而极限部分的优化往往只能增加10%左右。

成本基本上固定的，学会了就是学会了，编程的时间也不会用固定的差异，学习硬件与硬件变化的成本也应是固定的一段时间。而利益取决于应用的范围和开发程序的类型。   
按照2-8法则，一般优化成本200块，达到80%的效果，专家优化1000元的成本达到100%的效果。假设在一台机器上应用优化，最好的效果收益是100元。

* 如果应用在上1000台服务器上的同一个算法。一般优化的利润是 1000*100*0.8-200=78000，专家优化1000*100-1000=98000，那么做到极致是有意义的，收益更高。
* 另一种情况是，很多不同的算法，分布在不同的机器上，也就是根据客户的需求变化的。例如5台机器需要完成一种算法的优化，一般优化的利润是 5*100*0.8-200=200，专家优化5*100-1000=-500。所以完成合理的优化既满足，很多时候性能不足可以简单的增加额外的机器，硬件可能成本更低。

对于编程人员来说，更多遇到的是第二种情况，所以SSE-AVX效益最高的内容是simd部分，和简单的优化。花少量的努力完成合理的优化任务。

# 未来
未来的发展方向是异构计算，逻辑计算使用CPU方式，并行化计算采用CUDA的方式，大量简单的小核，完成大量并行的计算。而SSE-AVX的硬件则可能越来越向CUDA底层结构发展，而SSE-AVX本身则向着CUDA的底层汇编形式演化。   

最终异构计算也许会演化为通用的编程模型，而最终融入到编程语言中。单线程的控制逻辑与多线程的并行数据处理逻辑融合在一起。
